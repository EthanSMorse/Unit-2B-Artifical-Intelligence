{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpt_2_simple as gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt2.download_gpt2(model_name='124M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = gpt2.start_tf_sess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 10:12:16.393722: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint checkpoint/run1/model-15\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-15\n",
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 338024 tokens\n",
      "Training...\n",
      "[16 | 17.27] loss=3.52 avg=3.52\n",
      "[17 | 34.35] loss=3.44 avg=3.48\n",
      "[18 | 49.21] loss=3.57 avg=3.51\n",
      "[19 | 63.11] loss=3.46 avg=3.49\n",
      "[20 | 77.00] loss=3.42 avg=3.48\n",
      "[21 | 90.99] loss=3.37 avg=3.46\n",
      "[22 | 105.01] loss=3.30 avg=3.44\n",
      "[23 | 119.13] loss=3.60 avg=3.46\n",
      "[24 | 133.23] loss=3.49 avg=3.46\n",
      "[25 | 147.29] loss=3.24 avg=3.44\n",
      "[26 | 161.26] loss=3.38 avg=3.43\n",
      "[27 | 175.30] loss=3.40 avg=3.43\n",
      "[28 | 189.38] loss=3.42 avg=3.43\n",
      "[29 | 203.83] loss=3.44 avg=3.43\n",
      "[30 | 217.93] loss=3.54 avg=3.44\n",
      "[31 | 232.31] loss=3.43 avg=3.44\n",
      "[32 | 247.11] loss=3.25 avg=3.42\n",
      "[33 | 261.72] loss=3.31 avg=3.42\n",
      "[34 | 276.88] loss=3.49 avg=3.42\n",
      "[35 | 291.71] loss=3.47 avg=3.42\n",
      "[36 | 307.66] loss=3.42 avg=3.42\n",
      "[37 | 322.52] loss=3.50 avg=3.43\n",
      "[38 | 338.81] loss=3.51 avg=3.43\n",
      "[39 | 355.20] loss=3.49 avg=3.43\n",
      "[40 | 370.73] loss=3.50 avg=3.44\n",
      "[41 | 385.23] loss=3.41 avg=3.44\n",
      "[42 | 399.87] loss=3.41 avg=3.43\n",
      "[43 | 414.21] loss=3.36 avg=3.43\n",
      "[44 | 428.59] loss=3.25 avg=3.42\n",
      "[45 | 443.59] loss=3.39 avg=3.42\n",
      "[46 | 459.38] loss=3.40 avg=3.42\n",
      "[47 | 474.69] loss=3.26 avg=3.42\n",
      "[48 | 489.70] loss=3.11 avg=3.41\n",
      "[49 | 504.46] loss=3.52 avg=3.41\n",
      "[50 | 519.05] loss=3.34 avg=3.41\n",
      "[51 | 533.38] loss=3.47 avg=3.41\n",
      "[52 | 547.71] loss=3.25 avg=3.40\n",
      "[53 | 561.86] loss=3.45 avg=3.41\n",
      "[54 | 576.06] loss=3.10 avg=3.40\n",
      "[55 | 590.54] loss=3.29 avg=3.39\n",
      "[56 | 605.13] loss=2.87 avg=3.38\n",
      "[57 | 621.10] loss=3.38 avg=3.38\n",
      "[58 | 637.09] loss=3.30 avg=3.38\n",
      "[59 | 653.32] loss=2.99 avg=3.36\n",
      "[60 | 668.97] loss=3.38 avg=3.36\n",
      "[61 | 684.05] loss=3.17 avg=3.36\n",
      "[62 | 698.51] loss=3.09 avg=3.35\n",
      "[63 | 712.84] loss=3.36 avg=3.35\n",
      "[64 | 726.93] loss=3.27 avg=3.35\n",
      "[65 | 740.85] loss=3.19 avg=3.35\n",
      "[66 | 754.78] loss=3.16 avg=3.34\n",
      "[67 | 769.12] loss=3.17 avg=3.34\n",
      "[68 | 784.68] loss=2.99 avg=3.33\n",
      "[69 | 800.91] loss=3.31 avg=3.33\n",
      "[70 | 817.98] loss=3.40 avg=3.33\n",
      "[71 | 833.43] loss=3.12 avg=3.33\n",
      "[72 | 848.38] loss=3.10 avg=3.32\n",
      "[73 | 863.72] loss=3.17 avg=3.32\n",
      "[74 | 878.83] loss=3.28 avg=3.32\n",
      "[75 | 894.37] loss=3.16 avg=3.31\n",
      "[76 | 910.03] loss=3.30 avg=3.31\n",
      "[77 | 925.94] loss=3.37 avg=3.31\n",
      "[78 | 942.56] loss=3.39 avg=3.32\n",
      "[79 | 957.61] loss=3.23 avg=3.31\n",
      "[80 | 973.16] loss=3.14 avg=3.31\n",
      "[81 | 988.46] loss=3.27 avg=3.31\n",
      "[82 | 1003.80] loss=3.35 avg=3.31\n",
      "[83 | 1018.50] loss=3.25 avg=3.31\n",
      "[84 | 1033.09] loss=3.15 avg=3.31\n",
      "[85 | 1047.48] loss=3.18 avg=3.30\n",
      "[86 | 1062.31] loss=3.29 avg=3.30\n",
      "[87 | 1078.36] loss=3.13 avg=3.30\n",
      "[88 | 1093.95] loss=3.08 avg=3.30\n",
      "[89 | 1109.56] loss=3.09 avg=3.29\n",
      "[90 | 1124.11] loss=3.00 avg=3.29\n",
      "[91 | 1139.12] loss=3.38 avg=3.29\n",
      "[92 | 1154.94] loss=3.20 avg=3.29\n",
      "[93 | 1171.26] loss=3.11 avg=3.28\n",
      "[94 | 1187.79] loss=3.06 avg=3.28\n",
      "[95 | 1202.89] loss=3.11 avg=3.28\n",
      "[96 | 1218.01] loss=3.13 avg=3.27\n",
      "[97 | 1233.93] loss=3.20 avg=3.27\n",
      "[98 | 1249.37] loss=3.30 avg=3.27\n",
      "[99 | 1266.32] loss=3.06 avg=3.27\n",
      "[100 | 1282.60] loss=3.09 avg=3.27\n",
      "======== SAMPLE 1 ========\n",
      " mind, what is that?\n",
      "\n",
      "O, I am an earth-hating and wretched duke!\n",
      "What do you now have to do?\n",
      "\n",
      "O, you have my mind and I'll be with you,\n",
      "The earth-hating and damned duke; but you\n",
      "have no time; you have an hour; I shall\n",
      "look after you by my mind; you'll be gone in\n",
      "the absence of me: I will, and do make you\n",
      "your duke: but for me, I'll not go with you.\n",
      "I'll not go with you: I'll go with you.\n",
      "And to-morrow I will go with you.\n",
      "\n",
      "O, is the duke not now? Is he no man?\n",
      "\n",
      "O, that is no duke! that is the duke.\n",
      "\n",
      "Well, be you gone; I'll take you.\n",
      "\n",
      "O, so be it. O, so be it. Is he no man? O, so be it.\n",
      "\n",
      "And,\n",
      "\n",
      "Why, what, and why? Why, and why?\n",
      "\n",
      "Is it the case? Is it the case? Is it a lie?\n",
      "\n",
      "Well, if it is, then the duke's a duke: if it is, then it is.\n",
      "\n",
      "Well, let's meet and talk. We will have a talk.\n",
      "\n",
      "O, then:\n",
      "I have a word, and a word's worth of words. A word, for sure.\n",
      "\n",
      "I'ld be't but five or six years; and then I'ld come in.\n",
      "\n",
      "O, then I'll let you to-morrow night: or else I'll never meet you.\n",
      "\n",
      "But what was the news?\n",
      "\n",
      "Bearing,\n",
      "\n",
      "I'ld not yet get the news, but that we'll meet together again.\n",
      "\n",
      "O, 'twas not so:\n",
      "And a word before, what were the news of last night\n",
      "when you were alone in London?\n",
      "\n",
      "Ay, I was and not so. To-night I have arrived at some place,\n",
      "Where I must stay till,\n",
      "When we'll forget the world by ourselves,\n",
      "I shall be with you, to-morrow.\n",
      "\n",
      "Cousin:\n",
      "I think it shall be awhile.\n",
      "\n",
      "O, you're lost:\n",
      "I must do something to you.\n",
      "\n",
      "Cousin:\n",
      "'Tis well to be gone.\n",
      "\n",
      "O, then, you were lost.\n",
      "\n",
      "O, then, you were lost.\n",
      "\n",
      "Cousin:\n",
      "I am lost.\n",
      "\n",
      "O, then I am lost:\n",
      "But what I am lost in, is nothing of the world.\n",
      "I shall not go with you:\n",
      "I'll come to-morrow and see the duke, and then come I\n",
      "to meet him.\n",
      "\n",
      "O, he's lost.\n",
      "\n",
      "Bearing:\n",
      "Well, then, be gone, I'll leave you with him.\n",
      "\n",
      "O, then he's lost!\n",
      "\n",
      "Cousin:\n",
      "I'll know that.\n",
      "If the duke of Kent be lost,\n",
      "A very strange event shall take place in London.\n",
      "My heart is in London and I think no part of it\n",
      "Can know that he's lost.\n",
      "\n",
      "FRIAR PETER:\n",
      "It is indeed the story.\n",
      "\n",
      "O, it is.\n",
      "\n",
      "Bearing:\n",
      "I will not go with him: he must find his way\n",
      "To a town, and not to be found again: that's't there.\n",
      "Well, then, I cannot be seen before this hour;\n",
      "And when the duke of Kent is lost,\n",
      "O that my heart is in London and I think no part of it\n",
      "Can know that he's lost.\n",
      "\n",
      "O'MONTAGUE:\n",
      "I am not;\n",
      "I am not.\n",
      "\n",
      "Bearing:\n",
      "I would you did\n",
      "And I am lost.\n",
      "\n",
      "Bearing:\n",
      "I should say you are.\n",
      "\n",
      "O'MONTAGUE:\n",
      "Nay, you are, and I am lost.\n",
      "\n",
      "OXFORD:\n",
      "So shall you, young wench; and then you shall be lost,\n",
      "And then lost.\n",
      "\n",
      "Bearing:\n",
      "I should say you are.\n",
      "\n",
      "OXFORD:\n",
      "So shall ye; but then you shall be lost,\n",
      "And then lost, both of which are lost, although you\n",
      "Are lost; and that I may be lost,\n",
      "Even when I am lost by you, I dare say.\n",
      "\n",
      "O'MONTAGUE:\n",
      "Then this is not a man lost:\n",
      "I do know something. This is my Lord Northumberland:\n",
      "A man indeed who I think is lost.\n",
      "\n",
      "OXFORD:\n",
      "A man indeed lost.\n",
      "\n",
      "O'MONTAGUE:\n",
      "Well, that's all I have here,\n",
      "If the duke\n",
      "\n",
      "[101 | 1331.05] loss=3.15 avg=3.26\n",
      "[102 | 1347.47] loss=3.36 avg=3.27\n",
      "[103 | 1362.99] loss=3.12 avg=3.26\n",
      "[104 | 1378.15] loss=3.18 avg=3.26\n",
      "[105 | 1393.02] loss=3.25 avg=3.26\n",
      "[106 | 1410.29] loss=2.77 avg=3.25\n",
      "[107 | 1427.70] loss=3.10 avg=3.25\n",
      "[108 | 1443.55] loss=3.07 avg=3.25\n",
      "[109 | 1460.28] loss=3.24 avg=3.25\n",
      "[110 | 1474.80] loss=3.14 avg=3.25\n",
      "[111 | 1489.48] loss=2.94 avg=3.24\n",
      "[112 | 1504.52] loss=3.18 avg=3.24\n",
      "[113 | 1521.09] loss=2.93 avg=3.23\n",
      "[114 | 1538.55] loss=2.96 avg=3.23\n",
      "[115 | 1555.71] loss=2.92 avg=3.23\n",
      "Saving checkpoint/run1/model-115\n"
     ]
    }
   ],
   "source": [
    "gpt2.finetune(session, \"shakespeare.txt\", model_name=\"124M\", steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr Forlenza: Thou shalt not pass!\n",
      "But thou shalt not lose it.\n",
      "\n",
      "Bishop:\n",
      "What is the matter?\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "A bloody plague.\n",
      "\n",
      "Bishop:\n",
      "Wouldst thou, by and by, have gone to the church?\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "I would not have gone to the church.\n",
      "\n",
      "Bishop:\n",
      "Thou hast wronged the church.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "Ay, and I have gone to the church.\n",
      "\n",
      "Bishop:\n",
      "But this time thou shall not go to the church.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "I will not go to the church.\n",
      "\n",
      "Bishop:\n",
      "Thou hast wronged the church.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "Ay, and I have gone to the church.\n",
      "\n",
      "Bishop:\n",
      "Thou hast wronged the church.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "Ay, and I have gone to the church.\n",
      "\n",
      "Bishop:\n",
      "Thou hast wronged the church.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "Ay, and I have gone to the church.\n",
      "\n",
      "Bishop:\n",
      "Thou hast wronged the church.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "Ay, and I have gone to the church.\n",
      "\n",
      "Bishop:\n",
      "I am a Christian, and thou livest and breathest a Christian.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "And thou shalt live and breathe a Christian.\n",
      "\n",
      "Bishop:\n",
      "But thou livest and breathe a Christian.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "I know not what thou hast done to the church.\n",
      "\n",
      "Bishop:\n",
      "Thou hast done worship to the church.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "Thou hast done worship to the church.\n",
      "\n",
      "Bishop:\n",
      "I know not what thou hast done to the church.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "I know not what thou hast done to the church.\n",
      "\n",
      "Bishop:\n",
      "I know not what thou hast done to the church.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "I know not what thou hast done to the church.\n",
      "\n",
      "Bishop:\n",
      "I know not what thou hast done to the church.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "And I know thou art an apostate.\n",
      "\n",
      "Bishop:\n",
      "I know not what thou hast done to the church.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "I have not done to the church; I have not done.\n",
      "\n",
      "Bishop:\n",
      "I have not done to the church; I have not done.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "I have not done to the church; I have not done.\n",
      "\n",
      "Bishop:\n",
      "I have not done to the church; I have not done.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "I have not done to the church; I have not done.\n",
      "\n",
      "Bishop:\n",
      "I have not done to the church; I have not done.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "I have not done to the church; I have not done.\n",
      "\n",
      "Bishop:\n",
      "I have not done to the church; I have not done.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "I have not done to the church; I have not done.\n",
      "\n",
      "Bishop:\n",
      "I have not done to the church; I have not done.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "I have not done to the church; I have not done.\n",
      "\n",
      "Bishop:\n",
      "I have not done to the church; I have not done.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "I have not done to the church; I have not done.\n",
      "\n",
      "Bishop:\n",
      "I have not done to the church; I have not done.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "I have not done to the church; I have not done.\n",
      "\n",
      "Bishop:\n",
      "I have not done to the church; I have not done.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "I have not done to the church; I have not done.\n",
      "\n",
      "Bishop:\n",
      "I have not done to the church; I have not done.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "I have not done to the church; I have not done.\n",
      "\n",
      "Bishop:\n",
      "I have not done to the church; I have not done.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "I have not done to the church; I have not done.\n",
      "\n",
      "Bishop:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(session, prefix=\"Mr Forlenza: Thou shalt not pass!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Oct 13 2022, 09:48:40) [Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
